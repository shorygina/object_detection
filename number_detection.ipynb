{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshaping to format which CNN expects (batch, height, width, channels)\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2], 1).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2], 1).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function loading images to features and labels\n",
    "def load_images_to_data(image_label, image_directory, features_data, label_data):\n",
    "    list_of_files = os.listdir(image_directory)\n",
    "    for file in list_of_files:\n",
    "        image_file_name = os.path.join(image_directory, file)\n",
    "        if \".png\" in image_file_name:\n",
    "            img = Image.open(image_file_name).convert(\"L\")\n",
    "            img = np.resize(img, (28,28,1))\n",
    "            im2arr = np.array(img)\n",
    "            im2arr = im2arr.reshape(1,28,28,1)\n",
    "            features_data = np.append(features_data, im2arr, axis=0)\n",
    "            label_data = np.append(label_data, [image_label], axis=0)\n",
    "    return features_data, label_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize inputs from 0-255 to 0-1\n",
    "X_train/=255\n",
    "X_test/=255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OHE\n",
    "number_of_classes = 10\n",
    "y_train = np_utils.to_categorical(y_train, number_of_classes)\n",
    "y_test = np_utils.to_categorical(y_test, number_of_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (5, 5), input_shape=(X_train.shape[1], X_train.shape[2], 1), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(number_of_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/7\n",
      "60000/60000 [==============================] - 38s 641us/step - loss: 0.5199 - acc: 0.8331 - val_loss: 0.0792 - val_acc: 0.9757\n",
      "Epoch 2/7\n",
      "60000/60000 [==============================] - 57s 946us/step - loss: 0.1579 - acc: 0.9514 - val_loss: 0.0507 - val_acc: 0.9827\n",
      "Epoch 3/7\n",
      "60000/60000 [==============================] - 49s 810us/step - loss: 0.1208 - acc: 0.9633 - val_loss: 0.0421 - val_acc: 0.9866\n",
      "Epoch 4/7\n",
      "60000/60000 [==============================] - 44s 733us/step - loss: 0.1031 - acc: 0.9696 - val_loss: 0.0352 - val_acc: 0.9884\n",
      "Epoch 5/7\n",
      "60000/60000 [==============================] - 44s 729us/step - loss: 0.0917 - acc: 0.9718 - val_loss: 0.0347 - val_acc: 0.9883\n",
      "Epoch 6/7\n",
      "60000/60000 [==============================] - 37s 612us/step - loss: 0.0819 - acc: 0.9754 - val_loss: 0.0290 - val_acc: 0.9907\n",
      "Epoch 7/7\n",
      "60000/60000 [==============================] - 52s 873us/step - loss: 0.0744 - acc: 0.9771 - val_loss: 0.0260 - val_acc: 0.9906\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25943d1b710>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=7, batch_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the result\n",
    "model.save('models/mnistCNN.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics(Test loss & Test Accuracy): \n",
      "[0.0259809333654528, 0.9906]\n"
     ]
    }
   ],
   "source": [
    "# final evaluation\n",
    "metrics = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Metrics(Test loss & Test Accuracy): \")\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom tests"
   ]
  },
  {
   "attachments": {
    "0.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAAABGdBTUEAALGPC/xhBQAAAAlwSFlzAAASdAAAEnQB3mYfeAAAAMlJREFUSEvtlMsNwyAQRHFOlEYZlOGrq4AOKIsjJXDcIGeMNoSP/Mkhkd8FNOyOvLJ2xO+jtfbe00a6JwVvB1BKcbuCg+4hBBg0iDHu9kUrkXNOSvkS53mGurLPN82OPiJIDG6dfKEO4bNDeof7QhqCciJjDKQPUNE2nXBu5NJpKp8yw5oHzku5Ta/nD0xPBV1B2uh1WZqr3Q+HOsPVHoZDHXTU8ph/ZiccKsubBs8x2qETDpUftSwLbm2stbjtooh6Tmfwm+8gxBPDzh3nU9Y9EQAAAABJRU5ErkJggg=="
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![0.png](attachment:0.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open('test_imgs/0.png').convert(\"L\")\n",
    "img = np.resize(img, (28,28,1))\n",
    "im2arr = np.array(img)\n",
    "im2arr = im2arr.reshape(1,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict_classes(im2arr)\n",
    "print(y_pred)"
   ]
  },
  {
   "attachments": {
    "1.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAAABGdBTUEAALGPC/xhBQAAAAlwSFlzAAASdAAAEnQB3mYfeAAAAFtJREFUSEvt1KERwFAIREHKowzKoBPKi6QEJGF+zmcy4MI6TjwJrVfMfB0igqnP3fOICEx9T7GYGaY+JDNxj0Byo4OQ3OggJDc6CMm/Ruvhz0dVtYqTb399Q3QDa6+7/KjJbBYAAAAASUVORK5CYII="
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![1.png](attachment:1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open('test_imgs/1.png').convert(\"L\")\n",
    "img = np.resize(img, (28,28,1))\n",
    "im2arr = np.array(img)\n",
    "im2arr = im2arr.reshape(1,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict_classes(im2arr)\n",
    "print(y_pred)"
   ]
  },
  {
   "attachments": {
    "2.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAAABGdBTUEAALGPC/xhBQAAAAlwSFlzAAASdAAAEnQB3mYfeAAAANNJREFUSEvt1TESgyAQBVBN5dE4BqVH8CaUlByL0tLSkvzJ/nGQRGZJqDK+xrDAHzTOOtwqjDExxnQBU9ZaLlVC4rZtDLiw7ztXK63ryq1VXK0xzzM3peScYzXDuabQ45ghBJbOZBY41sDDkj3TNLF0JrPAscayLNjw8caFJALHmZHXdkfcOJYhD14b4W3jr16K95fVXxSJlYeudSdCh0TIO0ufRByTeb0S0YPzG2f1azhgveejN3KpXiWx0PBRkS6l1PxReYcO671n3kufP/A/DMMT/Z68N/7+mZ4AAAAASUVORK5CYII="
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![2.png](attachment:2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open('test_imgs/2.png').convert(\"L\")\n",
    "img = np.resize(img, (28,28,1))\n",
    "im2arr = np.array(img)\n",
    "im2arr = im2arr.reshape(1,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict_classes(im2arr)\n",
    "print(y_pred)"
   ]
  },
  {
   "attachments": {
    "3.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAAABGdBTUEAALGPC/xhBQAAAAlwSFlzAAASdAAAEnQB3mYfeAAAAPNJREFUSEvllLERgzAMRU0q2IwxKBmBTYCKklEYgxEoKZN/6MdnDiNsQ5W8BiHrPjr5C/MrlGU5z/N7DzJ1XbMiCq+cS9M0LA1HVwTrurL0wIvPA33fMzKm67rsS1EUkszzvKoqiR8APV42Gw2mKaKAqT0Zn5FYOQxEApfTmSrAGIzug2s5WoJn4VxatW1bloajK07TxLoo3FtWwLfTDQu3D8NApT0PGNarzrONRJ9arJxr2BSfXnJLNPGvqgAXL8siAx3HkdkzxPNAacRVBLg6HpwBOdZu4NXa0LtjQXsV6HkhYlMVn7uk7D7wdp2o9ScY8wFQvs+vsQbJYQAAAABJRU5ErkJggg=="
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![3.png](attachment:3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open('test_imgs/3.png').convert(\"L\")\n",
    "img = np.resize(img, (28,28,1))\n",
    "im2arr = np.array(img)\n",
    "im2arr = im2arr.reshape(1,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict_classes(im2arr)\n",
    "print(y_pred)"
   ]
  },
  {
   "attachments": {
    "4.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAAABGdBTUEAALGPC/xhBQAAAAlwSFlzAAASdAAAEnQB3mYfeAAAAKxJREFUSEvtk7ENAyEMRYE0jMYoNwIFDVNQwFBsQUkJDSJIOFEkQi4OpxTJvcbflviywZD/5gJxQAhhraWUeu+htE4IodaaUoIcA4U40By7aM128T4M4qGgTZVSMUbnHOQo2vgdyG+UUp7WH0F3ytj+EZzptm2gCOGcgxrYf/0ZL7Zi2mnOGRSeqanWGhQe9GLfr+WT8Vc4TY/nh01XftoUKWXbf2MM5CffgJArP0o9pivIcuEAAAAASUVORK5CYII="
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![4.png](attachment:4.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open('test_imgs/4.png').convert(\"L\")\n",
    "img = np.resize(img, (28,28,1))\n",
    "im2arr = np.array(img)\n",
    "im2arr = im2arr.reshape(1,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict_classes(im2arr)\n",
    "print(y_pred)"
   ]
  },
  {
   "attachments": {
    "5.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAAEnQAABJ0Ad5mH3gAAADnSURBVEhL7ZSxDYMwEEVNQoHYhw1cUDAEpUdgFKig8yLsQcsGiAKRk/xBlrEtcJIG8Rp/zuevK+7DbkGe58MwrG7otixLdJ9kHEe8djNNE7o1XjhtpGkK5abrOiiNCKcNGkSJKPK1HfFNGszNTPXFClkjHdg4CHSnHYSBA2oQQqBb443TxrIsnHOl67rOsmye571CxHFcFAUV+75H6RuqqsK0jlAFkiQJXLeM7FyLisFuZ0TuSdTv8Zke//z0qbadskRatV3DcPSABxu+SZumgfJCYYMKgLa9bVvMtq5SSqrg7uG/MPYBuGAd6FB6mA0AAAAASUVORK5CYII="
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![5.png](attachment:5.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open('test_imgs/5.png').convert(\"L\")\n",
    "img = np.resize(img, (28,28,1))\n",
    "im2arr = np.array(img)\n",
    "im2arr = im2arr.reshape(1,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict_classes(im2arr)\n",
    "print(y_pred)"
   ]
  },
  {
   "attachments": {
    "6.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAAABGdBTUEAALGPC/xhBQAAAAlwSFlzAAASdAAAEnQB3mYfeAAAAPRJREFUSEvdlbEVgzAMBSEVozEGY7AJIzAKY1BSUlLCD/r4yWAIEinycg2KJR+2wCT7L6qq6vt+3kCMEeYc7HSBaZpYYaIsy6ROaJqGdSaGYaBgpW3boiiYc0OZS5fzegA6CfL8tOaMF68xaCijL6IbyqHn0Od9yul+QSeBo6Eg3dNAeFufniKwbv3NOI6MYjz34NRLcFJtXs7b6LqOUYzNi+owjUOKuq4lCwxfFj2NQzEfC9JwxjyfbZBpk/S6A0CygL/voDeYXCxzJinQi915cSgkBTh0E71YEF54GPWhkGIDO+8R5//KhddpDBzVT40/QJYthBXslCSkk64AAAAASUVORK5CYII="
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![6.png](attachment:6.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open('test_imgs/6.png').convert(\"L\")\n",
    "img = np.resize(img, (28,28,1))\n",
    "im2arr = np.array(img)\n",
    "im2arr = im2arr.reshape(1,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict_classes(im2arr)\n",
    "print(y_pred)"
   ]
  },
  {
   "attachments": {
    "7.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAAABGdBTUEAALGPC/xhBQAAAAlwSFlzAAASdAAAEnQB3mYfeAAAANpJREFUSEvtlDEOhCAQRc1WHMEjeQxLj2DpHSyIjbHjHJzEkpLSQhJ2En42ZHVdkKk2+wqdDOExhnGqPzFN06zr6r2nZ9u2yBYSjF/JO7Lve+xLI8Oepd62DdtKOB6JhUK6roPPeyklsiVQh1hrg1EphWwJsZEQQmDhNm9Gng83xsDHZRyGAT4uY3zd9y/nNQQuyJ4PiUPg9Hd64H1gmiZElyzLgigd/j4n4h5i6HOCyoSPq4eIuEykChnHET7GMvd9D0bnHFLJfGwprXUI5nkOAQ91XSP6UarqCTjAmsnPY2TAAAAAAElFTkSuQmCC"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![7.png](attachment:7.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open('test_imgs/7.png').convert(\"L\")\n",
    "img = np.resize(img, (28,28,1))\n",
    "im2arr = np.array(img)\n",
    "im2arr = im2arr.reshape(1,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict_classes(im2arr)\n",
    "print(y_pred)"
   ]
  },
  {
   "attachments": {
    "8.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAAABGdBTUEAALGPC/xhBQAAAAlwSFlzAAASdAAAEnQB3mYfeAAAAQ1JREFUSEvNlb0Ng0AMRo9UjMYYlIzABoxAmZKxKCkpKS8W/mSZ+0mwFSl5RdAZ8+SLDxN+Rtd167rGGOl3GAZE3YhOQ5G+75HhYNs2mK4cx+H3wnHyPMHi9CLJCj3JCqxDGMeRIwRCVri0ZLNsJLC2Il0SL7WOIwTnmNGbJW9yEpDkQHs18zwjw4Her+A3Fk9+0jQbZNz3HaYrTm9upP0mTTN79dup/77Ei+hN8FypIdprKJaGGx6qnESqke8aipW9L8uC0BVdLEIfQXqMbdsilIGMirTBVSGpTVO4y7zPeeBawn/Ic3Qfil8kz6CqTRB6Zadp8g+qmjfBPFao9fqLlOMfVIKu/Qu6/yCEF5UrNS0wUwePAAAAAElFTkSuQmCC"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![8.png](attachment:8.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open('test_imgs/8.png').convert(\"L\")\n",
    "img = np.resize(img, (28,28,1))\n",
    "im2arr = np.array(img)\n",
    "im2arr = im2arr.reshape(1,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict_classes(im2arr)\n",
    "print(y_pred)"
   ]
  },
  {
   "attachments": {
    "9.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAAEnQAABJ0Ad5mH3gAAADgSURBVEhL7ZQxEoUgDAUpPZrHsPQI3MTS0mNZWlJS8t9M3jgREUHs/NsZkxUIxvw50/f9uq7hCCLDMDCjFhidczSleGLfto3VWerULAphmiaGjLHWMqrw3vP1LawIgc9HtB3S0sWy4kIq7Odeulgxgswq9LkzlAcfl+yr3Y3jKAlgWRZG85x7gkZDJG+jC9d1ncTvSfY6CQsKKfQyuxZscJ5nOo7oi9yE7hJDjegulfY9D67Xw74ngS6ahE2nmRysrcZosOIcm3YdGVt1gh4Zr93Hfay8ZgTym75p/AjG/ABFJ+pdrfddAgAAAABJRU5ErkJggg=="
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![9.png](attachment:9.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open('test_imgs/9.png').convert(\"L\")\n",
    "img = np.resize(img, (28,28,1))\n",
    "im2arr = np.array(img)\n",
    "im2arr = im2arr.reshape(1,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict_classes(im2arr)\n",
    "print(y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
